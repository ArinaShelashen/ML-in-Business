{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc91b581",
   "metadata": {},
   "source": [
    "## Task2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f4f15",
   "metadata": {},
   "source": [
    "Модифицировать код функции get_user_embedding таким образом, чтобы считалось не среднее (как в примере np.mean), а медиана. Применить такое преобразование к данным, обучить модель прогнозирования оттока и посчитать метрики качества и сохранить их: roc auc, precision/recall/f_score (для 3 последних - подобрать оптимальный порог с помощью precision_recall_curve, как это делалось на уроке)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ed31dc",
   "metadata": {},
   "source": [
    "**Импорт библиотек и инструментов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "a0178ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'ignore'}"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from razdel import tokenize\n",
    "import pymorphy2\n",
    "np.seterr(invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "85fcc308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "433fa557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "2338fc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc1ffc2",
   "metadata": {},
   "source": [
    "**Загрузка данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "09fda0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Заместитель председателяnправительства РФnСерг...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>Матч 1/16 финала Кубка России по футболу был п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>Форвард «Авангарда» Томаш Заборский прокоммент...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                              title\n",
       "0       6  Заместитель председателяnправительства РФnСерг...\n",
       "1    4896  Матч 1/16 финала Кубка России по футболу был п...\n",
       "2    4897  Форвард «Авангарда» Томаш Заборский прокоммент..."
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv('materials.csv')\n",
    "news.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "a463d4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>[293672, 293328, 293001, 293622, 293126, 1852]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>[3405, 1739, 2972, 1158, 1599, 322665]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>[1845, 2009, 2356, 1424, 2939, 323389]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u101138</td>\n",
       "      <td>[5933, 6186, 5055, 6977, 5206, 488389]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u108248</td>\n",
       "      <td>[707, 1144, 2532, 2928, 3133, 324592]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u106662</td>\n",
       "      <td>[323868, 323426, 324267, 322426, 324104, 1550]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u105949</td>\n",
       "      <td>[293138, 294471, 295012, 294736, 293949, 3544]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>u102457</td>\n",
       "      <td>[6928, 5009, 6940, 7629, 7644, 512736]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>u104124</td>\n",
       "      <td>[322838, 324699, 322991, 322120, 324327, 472331]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>u101386</td>\n",
       "      <td>[7827, 6427, 7394, 7151, 6335, 487254]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                                          articles\n",
       "0  u105138    [293672, 293328, 293001, 293622, 293126, 1852]\n",
       "1  u108690            [3405, 1739, 2972, 1158, 1599, 322665]\n",
       "2  u108339            [1845, 2009, 2356, 1424, 2939, 323389]\n",
       "3  u101138            [5933, 6186, 5055, 6977, 5206, 488389]\n",
       "4  u108248             [707, 1144, 2532, 2928, 3133, 324592]\n",
       "5  u106662    [323868, 323426, 324267, 322426, 324104, 1550]\n",
       "6  u105949    [293138, 294471, 295012, 294736, 293949, 3544]\n",
       "7  u102457            [6928, 5009, 6940, 7629, 7644, 512736]\n",
       "8  u104124  [322838, 324699, 322991, 322120, 324327, 472331]\n",
       "9  u101386            [7827, 6427, 7394, 7151, 6335, 487254]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv(\"users_articles.csv\")\n",
    "users.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a075d34d",
   "metadata": {},
   "source": [
    "**Дополняем стоп-слова, очищаем текст от стоп-слов, символов, лемматизируем**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "4916eb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_ru = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "5e6d0722",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stopwords.txt', encoding = 'UTF-8') as f:\n",
    "    add_stopwords = [w.strip() for w in f.readlines() if w]\n",
    "stopwords_ru += add_stopwords   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "30454156",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "d3bac31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = text.lower()\n",
    "    text = text.strip('\\n').strip('\\r').strip('\\t')\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
    "\n",
    "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n",
    "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
    "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
    "    text = re.sub('n', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "cache = {}\n",
    "\n",
    "def lemmatization(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    tokens = list(tokenize(text))\n",
    "    words = [_.text for _ in tokens]\n",
    "    words_lem = []\n",
    "    for w in words:\n",
    "        if w[0] == '-':\n",
    "            w = w[1:]\n",
    "        if len(w) > 1:\n",
    "            if w in cache:\n",
    "                words_lem.append(cache[w])\n",
    "            else:\n",
    "                temp_cache = cache[w] = morph.parse(w)[0].normal_form\n",
    "                words_lem.append(temp_cache)\n",
    "    words_lem_without_stopwords = [w for w in words_lem if not w in stopwords_ru]\n",
    "    \n",
    "    return words_lem_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "080ff552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 3s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Очистка текста\n",
    "news['title'] = news['title'].apply(lambda x: clean_text(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "3d8080ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15min 42s\n",
      "Wall time: 16min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Лемматизация текста\n",
    "news['title'] = news['title'].apply(lambda x: lemmatization(x), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7ff7eb",
   "metadata": {},
   "source": [
    "**Doc2Bow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "828d3996",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = [t for t in news['title'].values]\n",
    "\n",
    "common_dictionary = Dictionary(all_texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in all_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "3be2d108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 58.8 s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda = LdaModel(common_corpus, num_topics = 20, id2word=common_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "b80b405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_file = datapath('model.lda')\n",
    "lda.save(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "2596576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b277c76",
   "metadata": {},
   "source": [
    "**Разбиваем тексты по темам**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "f3b0c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_vector(text):\n",
    "    unseen_doc = common_dictionary.doc2bow(text)\n",
    "    lda_tuple = lda[unseen_doc]\n",
    "    not_null_topics = dict(zip([i[0] for i in lda_tuple], [i[1] for i in lda_tuple]))\n",
    "    \n",
    "    output_vector = []\n",
    "    for i in range(20):\n",
    "        if i not in not_null_topics:\n",
    "            output_vector.append(0)\n",
    "        else:\n",
    "            output_vector.append(not_null_topics[i])\n",
    "    return np.array(output_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "a1782e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>topic_11</th>\n",
       "      <th>topic_12</th>\n",
       "      <th>topic_13</th>\n",
       "      <th>topic_14</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.860255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>0.508708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075989</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>0.071372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4898</td>\n",
       "      <td>0.143635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4899</td>\n",
       "      <td>0.067217</td>\n",
       "      <td>0.106137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.703793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id   topic_0   topic_1  topic_2   topic_3  topic_4  topic_5   topic_6  \\\n",
       "0       6  0.000000  0.040939      0.0  0.860255      0.0      0.0  0.000000   \n",
       "1    4896  0.508708  0.000000      0.0  0.000000      0.0      0.0  0.000000   \n",
       "2    4897  0.071372  0.000000      0.0  0.000000      0.0      0.0  0.000000   \n",
       "3    4898  0.143635  0.000000      0.0  0.000000      0.0      0.0  0.000000   \n",
       "4    4899  0.067217  0.106137      0.0  0.703793      0.0      0.0  0.099292   \n",
       "\n",
       "    topic_7   topic_8  ...  topic_10  topic_11  topic_12  topic_13  topic_14  \\\n",
       "0  0.078457  0.000000  ...  0.000000  0.000000       0.0       0.0  0.012478   \n",
       "1  0.000000  0.000000  ...  0.000000  0.392924       0.0       0.0  0.000000   \n",
       "2  0.141460  0.000000  ...  0.312906  0.000000       0.0       0.0  0.000000   \n",
       "3  0.000000  0.338997  ...  0.445054  0.000000       0.0       0.0  0.000000   \n",
       "4  0.000000  0.000000  ...  0.000000  0.000000       0.0       0.0  0.000000   \n",
       "\n",
       "   topic_15  topic_16  topic_17  topic_18  topic_19  \n",
       "0       0.0       0.0  0.000000  0.000000       0.0  \n",
       "1       0.0       0.0  0.000000  0.075989       0.0  \n",
       "2       0.0       0.0  0.452655  0.000000       0.0  \n",
       "3       0.0       0.0  0.062020  0.000000       0.0  \n",
       "4       0.0       0.0  0.000000  0.000000       0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_matrix = pd.DataFrame([get_lda_vector(text) for text in news['title'].values])\n",
    "topic_matrix.columns = ['topic_{}'.format(i) for i in range(20)]\n",
    "topic_matrix['doc_id'] = news['doc_id'].values\n",
    "topic_matrix = topic_matrix[['doc_id']+['topic_{}'.format(i) for i in range(20)]]\n",
    "topic_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "b2f1c97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dict = dict(zip(topic_matrix['doc_id'].values,topic_matrix[['topic_{}'.format(i) for i in range(20)]].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf334c31",
   "metadata": {},
   "source": [
    "**Характеризуем пользователей интересующими их темами**<br>\n",
    "*с разными усреднениями(среднее, медиана, макс)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "c385940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding_mean(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.mean(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "7881bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding_med(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.median(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "67d06706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding_max(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.max(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "fabbb80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings_mean = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding_mean(x),1)])\n",
    "user_embeddings_mean.columns = ['topic_{}'.format(i) for i in range(20)]\n",
    "user_embeddings_mean['uid'] = users['uid'].values\n",
    "user_embeddings_mean = user_embeddings_mean[['uid']+['topic_{}'.format(i) for i in range(20)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "56dd9efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings_med = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding_med(x),1)])\n",
    "user_embeddings_med.columns = ['topic_{}'.format(i) for i in range(20)]\n",
    "user_embeddings_med['uid'] = users['uid'].values\n",
    "user_embeddings_med = user_embeddings_med[['uid']+['topic_{}'.format(i) for i in range(20)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "e3df815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings_max = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding_max(x),1)])\n",
    "user_embeddings_max.columns = ['topic_{}'.format(i) for i in range(20)]\n",
    "user_embeddings_max['uid'] = users['uid'].values\n",
    "user_embeddings_max = user_embeddings_max[['uid']+['topic_{}'.format(i) for i in range(20)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "aefb91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv(\"users_churn.csv\")\n",
    "X_mean = pd.merge(user_embeddings_mean, target, 'left')\n",
    "X_med = pd.merge(user_embeddings_med, target, 'left')\n",
    "X_max = pd.merge(user_embeddings_max, target, 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6fb333",
   "metadata": {},
   "source": [
    "**Расчёт метрик для среднего**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "06dc8782",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_mean[['topic_{}'.format(i) for i in range(20)]], \n",
    "                                                    X_mean['churn'], random_state=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "c71c8796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "bbff7062",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = logreg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "d27e7611",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_mean, recall_mean, thresholds_mean = precision_recall_curve(y_test, preds)\n",
    "fscore_mean = (2 * precision_mean * recall_mean) / (precision_mean + recall_mean)\n",
    "fscore_mean = np.nan_to_num(fscore_mean)\n",
    "ix = np.argmax(fscore_mean)\n",
    "best_fscore_mean =  round(fscore_mean[ix],3)\n",
    "best_precision_mean =  round(precision_mean[ix],3)\n",
    "best_recall_mean =  round(recall_mean[ix],3)\n",
    "rocauc_mean =  round(roc_auc_score(y_test, preds),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff125f5d",
   "metadata": {},
   "source": [
    "**Расчёт метрик для медианы**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "5a770ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_med[['topic_{}'.format(i) for i in range(20)]], \n",
    "                                                    X_med['churn'], random_state=26)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "preds = logreg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "a26bba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_med, recall_med, thresholds_med = precision_recall_curve(y_test, preds)\n",
    "fscore_med = (2 * precision_med * recall_med) / (precision_med + recall_med)\n",
    "fscore_med = np.nan_to_num(fscore_med)\n",
    "ix = np.argmax(fscore_med)\n",
    "best_fscore_med =  round(fscore_med[ix],3)\n",
    "best_precision_med =  round(precision_med[ix],3)\n",
    "best_recall_med =  round(recall_med[ix],3)\n",
    "rocauc_med =  round(roc_auc_score(y_test, preds),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf18c94",
   "metadata": {},
   "source": [
    "**Расчёт метрик для максимума**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "d185edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_max[['topic_{}'.format(i) for i in range(20)]], \n",
    "                                                    X_max['churn'], random_state=26)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "preds = logreg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "1fd98baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_max, recall_max, thresholds_max = precision_recall_curve(y_test, preds)\n",
    "fscore_max = (2 * precision_max * recall_max) / (precision_max + recall_max)\n",
    "fscore_max = np.nan_to_num(fscore_max)\n",
    "ix = np.argmax(fscore_max)\n",
    "best_fscore_max = round(fscore_max[ix],3)\n",
    "best_precision_max =  round(precision_max[ix],3)\n",
    "best_recall_max =  round(recall_max[ix],3)\n",
    "rocauc_max =  round(roc_auc_score(y_test, preds),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47276fa7",
   "metadata": {},
   "source": [
    "**Объединяем результаты в одну таблицу**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "1a65cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {'Metrics':['F-Score', 'Precision', 'Recall', 'Roc Auc'],\\\n",
    "         'Mean':[best_fscore_mean,best_precision_mean,best_recall_mean,rocauc_mean],\\\n",
    "        'Median':[best_fscore_med,best_precision_med,best_recall_med,rocauc_med],\\\n",
    "        'Max':[best_fscore_max,best_precision_max,best_recall_max,rocauc_max]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "865f56de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F-Score</th>\n",
       "      <td>0.758</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.745</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.771</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc Auc</th>\n",
       "      <td>0.966</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Max   Mean  Median\n",
       "Metrics                        \n",
       "F-Score    0.758  0.560   0.629\n",
       "Precision  0.745  0.425   0.571\n",
       "Recall     0.771  0.821   0.700\n",
       "Roc Auc    0.966  0.909   0.943"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(pd.DataFrame(table),\n",
    "               index=[\"Metrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da676ab",
   "metadata": {},
   "source": [
    "*Лучшие результаты(F-score) - для расчётов по максимуму. Возможное объяснение: учитываются ВСЕ интересующие пользователя темы с достаточным весом. При использовании среднего/медианы вес темы очень занизится, даже если он достаточно высок в 1-2 статьях. Модель может посчитать, что тема не интересна пользователю, раз он прочитал только 1 статью, хотя это может быть не так.*<br><br>\n",
    "*Медиана показывает лучшие результаты, чем среднее, т.к. данных не так много, следовательно распределение будет далеко от нормального. А значит и среднее слишком смещено от медианы*<br><br>\n",
    "*Если смотреть отдельно по метрикам, у среднего полнота лучшая, т.к. из усреднения берется всё подряд, ничего лишнего не упускается, зато из-за этого сильно страдает точность, тут max работает аккуратнее* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d851e063",
   "metadata": {},
   "source": [
    "**Посчитаем вес каждого документа по популярности слов, встречающихся в этом документе; просуммируем idf слов в каждом документе - так получим вес документа; умножим полученный ранее вектор для документа на его \"уникальность\"(суммарный idf).**<br>\n",
    "*Для вектора пользователя будем использовать максимум как самый успешный показатель из прошлых испытаний*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "2e7ca17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "b889910a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_12912\\2474920516.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  news_tfidf['title'][i] = temp\n"
     ]
    }
   ],
   "source": [
    "#Очищенный и лемматизированный текст в виде отдельных слов соберем обратно в текст\n",
    "news_tfidf = news.copy(deep=True)\n",
    "temp = ''\n",
    "for  i in range(news_tfidf.shape[0]):\n",
    "    for k in range(len(news_tfidf['title'][i])):\n",
    "        temp += news_tfidf['title'][i][k] + ' '\n",
    "    news_tfidf['title'][i] = temp\n",
    "    temp = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "e340a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Векторизуем все тексты\n",
    "texts_tfidf = [t for t in news_tfidf['title']]\n",
    "X = tf_idf.fit_transform(texts_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "df54b06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_12912\\3817677052.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  news_tfidf['idf'][i] = round(X[i].toarray().sum(), 5)\n"
     ]
    }
   ],
   "source": [
    "# Добавим к датафрейму значение idf для каждого документа (сумма idf его слов)\n",
    "news_tfidf['idf'] = 0\n",
    "for i in range(X.shape[0]):\n",
    "    news_tfidf['idf'][i] = round(X[i].toarray().sum(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "6f85249f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>idf</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>topic_11</th>\n",
       "      <th>topic_12</th>\n",
       "      <th>topic_13</th>\n",
       "      <th>topic_14</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.860255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>5</td>\n",
       "      <td>0.508708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075989</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>5</td>\n",
       "      <td>0.071372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  idf   topic_0   topic_1  topic_2   topic_3  topic_4  topic_5  \\\n",
       "0       6    8  0.000000  0.040939      0.0  0.860255      0.0      0.0   \n",
       "1    4896    5  0.508708  0.000000      0.0  0.000000      0.0      0.0   \n",
       "2    4897    5  0.071372  0.000000      0.0  0.000000      0.0      0.0   \n",
       "\n",
       "   topic_6   topic_7  ...  topic_10  topic_11  topic_12  topic_13  topic_14  \\\n",
       "0      0.0  0.078457  ...  0.000000  0.000000       0.0       0.0  0.012478   \n",
       "1      0.0  0.000000  ...  0.000000  0.392924       0.0       0.0  0.000000   \n",
       "2      0.0  0.141460  ...  0.312906  0.000000       0.0       0.0  0.000000   \n",
       "\n",
       "   topic_15  topic_16  topic_17  topic_18  topic_19  \n",
       "0       0.0       0.0  0.000000  0.000000       0.0  \n",
       "1       0.0       0.0  0.000000  0.075989       0.0  \n",
       "2       0.0       0.0  0.452655  0.000000       0.0  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Добавим значение idf в матрицу тем\n",
    "topic_matrix['idf'] = news_tfidf['idf'].values\n",
    "topic_matrix = topic_matrix[['doc_id']+['idf']+['topic_{}'.format(i) for i in range(20)]]\n",
    "topic_matrix.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "e38762b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Умножим полученные вероятности тем на idf \n",
    "for i in doc_dict.keys():\n",
    "    tempidf = topic_matrix.loc[topic_matrix['doc_id']==i, 'idf']\n",
    "    doc_dict[i] *= float(tempidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "02c85f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding_max_idf(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.max(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "28ad531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получим вектор пользователя (уже с учетом idf)\n",
    "user_embeddings_max_idf = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding_max_idf(x),1)])\n",
    "user_embeddings_max_idf.columns = ['topic_{}'.format(i) for i in range(20)]\n",
    "user_embeddings_max_idf['uid'] = users['uid'].values\n",
    "user_embeddings_max_idf = user_embeddings_max_idf[['uid']+['topic_{}'.format(i) for i in range(20)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "b422e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_max_idf = pd.merge(user_embeddings_max_idf, target, 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "e2dd168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_max_idf[['topic_{}'.format(i) for i in range(20)]], \n",
    "                                                    X_max_idf['churn'], random_state=26)\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "preds = logreg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "d4d7e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_max_idf, recall_max_idf, thresholds_max_idf = precision_recall_curve(y_test, preds)\n",
    "fscore_max_idf = (2 * precision_max_idf * recall_max_idf) / (precision_max_idf + recall_max_idf)\n",
    "fscore_max_idf = np.nan_to_num(fscore_max_idf)\n",
    "ix = np.argmax(fscore_max_idf)\n",
    "best_fscore_max_idf = round(fscore_max_idf[ix],3)\n",
    "best_precision_max_idf =  round(precision_max_idf[ix],3)\n",
    "best_recall_max_idf =  round(recall_max_idf[ix],3)\n",
    "rocauc_max_idf =  round(roc_auc_score(y_test, preds),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "343f1b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вносим полученные метрики в таблицу\n",
    "table['Max_idf'] = [best_fscore_max_idf,best_precision_max_idf,best_recall_max_idf,rocauc_max_idf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "44fb35ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max</th>\n",
       "      <th>Max_idf</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F-Score</th>\n",
       "      <td>0.758</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.745</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.771</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc Auc</th>\n",
       "      <td>0.966</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Max  Max_idf   Mean  Median\n",
       "Metrics                                 \n",
       "F-Score    0.758    0.817  0.560   0.629\n",
       "Precision  0.745    0.846  0.425   0.571\n",
       "Recall     0.771    0.789  0.821   0.700\n",
       "Roc Auc    0.966    0.983  0.909   0.943"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(pd.DataFrame(table),\n",
    "               index=[\"Metrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc60cbb9",
   "metadata": {},
   "source": [
    "**Учет уникальности статьи заметно увеличил значения метрик, это самые лучшие результаты**<br>\n",
    "*Возможная причина - отсеяли \"мусор\", очень популярные статьи, которые в любом случае читают многие, т.е. они не влияют на отписку**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
